# ğŸš€ Pipeline MLOps/DataOps - DÃ©tection d'Anomalies IT

## ğŸ“‹ Table des MatiÃ¨res

- [Vue d'Ensemble](#-vue-densemble)
- [Architecture](#-architecture)
- [ModÃ¨les ImplÃ©mentÃ©s](#-modÃ¨les-implÃ©mentÃ©s)
- [Installation](#-installation)
- [Utilisation Rapide](#-utilisation-rapide)
- [Documentation DÃ©taillÃ©e](#-documentation-dÃ©taillÃ©e)
- [Configuration](#-configuration)
- [DÃ©ploiement](#-dÃ©ploiement)
- [Tests](#-tests)
- [Monitoring](#-monitoring)
- [Contribution](#-contribution)
- [Support](#-support)

## ğŸ¯ Vue d'Ensemble

Cette pipeline MLOps/DataOps complÃ¨te permet la **dÃ©tection d'anomalies en temps rÃ©el** dans les infrastructures IT. Elle intÃ¨gre des algorithmes de Machine Learning avancÃ©s avec une architecture cloud-native pour une supervision intelligente et automatisÃ©e.

### âœ¨ FonctionnalitÃ©s Principales

- ğŸ¤– **3 ModÃ¨les ML** : Isolation Forest, Random Forest, LSTM
- ğŸ”„ **Pipeline AutomatisÃ©e** : EntraÃ®nement, validation, dÃ©ploiement
- ğŸ“Š **Monitoring Temps RÃ©el** : Grafana, Prometheus, MLflow
- ğŸ³ **Kubernetes Native** : Scalable et cloud-ready
- ğŸ” **Interface CLI** : Utilisation simple et automation
- ğŸ“ˆ **Comparaison Automatique** : SÃ©lection du meilleur modÃ¨le

### ğŸª Cas d'Usage

- âœ… DÃ©tection proactive d'incidents systÃ¨me
- âœ… Monitoring de performance des serveurs
- âœ… Analyse de logs en temps rÃ©el
- âœ… PrÃ©diction de pannes d'infrastructure
- âœ… Optimisation des ressources IT

## ğŸ—ï¸ Architecture

```mermaid
graph TB
    subgraph "ğŸ”„ Pipeline MLOps"
        A[DonnÃ©es IT] --> B[Feature Engineering]
        B --> C[EntraÃ®nement ModÃ¨les]
        C --> D[Comparaison & SÃ©lection]
        D --> E[DÃ©ploiement MLflow]
    end
    
    subgraph "ğŸ¤– ModÃ¨les ML"
        F[Isolation Forest<br/>Non-supervisÃ©]
        G[Random Forest<br/>SupervisÃ©]
        H[LSTM<br/>SÃ©quences Temporelles]
    end
    
    subgraph "ğŸ­ Infrastructure"
        I[Kubernetes]
        J[Kafka Streaming]
        K[MLflow Registry]
        L[Prometheus/Grafana]
    end
    
    C --> F
    C --> G
    C --> H
    E --> K
    J --> C
    I --> J
    I --> K
    I --> L
```

### ğŸ“¦ Composants

| Composant | Description | Technologie |
|-----------|-------------|-------------|
| **Base Model** | Classe abstraite commune | Python OOP |
| **Isolation Forest** | DÃ©tection non-supervisÃ©e | scikit-learn |
| **Random Forest** | Classification supervisÃ©e | scikit-learn |
| **LSTM** | Analyse temporelle | TensorFlow |
| **Model Comparator** | Comparaison automatique | MLflow |
| **Main Orchestrator** | Pipeline complÃ¨te | CLI + Configuration |

## ğŸ¤– ModÃ¨les ImplÃ©mentÃ©s

### 1ï¸âƒ£ Isolation Forest
```python
from isolation_forest_model import IsolationForestModel

model = IsolationForestModel(contamination=0.05, n_estimators=100)
model.fit(X_train)
predictions = model.predict(X_test)
```

**ğŸ“Š CaractÃ©ristiques :**
- âœ… Non-supervisÃ© (pas besoin de labels)
- âœ… Excellent pour nouvelles anomalies
- âœ… Rapide et scalable
- âœ… Faible taux de faux positifs

### 2ï¸âƒ£ Random Forest
```python
from random_forest_model import RandomForestModel

model = RandomForestModel(n_estimators=100, class_weight='balanced')
model.fit(X_train, y_train)
probabilities = model.get_anomaly_probabilities(X_test)
```

**ğŸ“Š CaractÃ©ristiques :**
- âœ… Haute prÃ©cision sur donnÃ©es Ã©tiquetÃ©es
- âœ… Importance des features
- âœ… Robuste au surapprentissage
- âœ… Gestion classes dÃ©sÃ©quilibrÃ©es

### 3ï¸âƒ£ LSTM (Deep Learning)
```python
from lstm_model import LSTMModel

model = LSTMModel(sequence_length=10, lstm_units=[50, 25])
model.fit(X_train, y_train)
temporal_analysis = model.detect_temporal_anomalies(X_test)
```

**ğŸ“Š CaractÃ©ristiques :**
- âœ… Analyse sÃ©quences temporelles
- âœ… DÃ©tection patterns complexes
- âœ… PrÃ©diction d'anomalies futures
- âœ… MÃ©moire Ã  long terme

## ğŸš€ Installation

### PrÃ©requis

- ğŸ Python 3.8+
- ğŸ³ Docker & Kubernetes
- ğŸ”§ MLflow Server
- ğŸ“Š Prometheus/Grafana (optionnel)

### Installation Rapide

```bash
# 1. Cloner le repository
git clone https://github.com/your-org/mlops-anomaly-detection.git
cd mlops-anomaly-detection

# 2. Installer les dÃ©pendances
pip install -r requirements.txt

# 3. Configuration initiale
cp config.json.example config.json

# 4. Test de l'installation
python test_complete_pipeline.py
```

### Installation avec Docker

```bash
# Build de l'image
docker build -t mlops-anomaly-detection .

# Lancement du container
docker run -p 8000:8000 -v $(pwd)/models:/app/models mlops-anomaly-detection
```

### DÃ©ploiement Kubernetes

```bash
# DÃ©ploiement complet
./deploy_mlops_pipeline.sh

# Validation du dÃ©ploiement
python validate_pipeline.py
```

## ğŸƒ Utilisation Rapide

### 1. EntraÃ®nement Rapide

```bash
# EntraÃ®nement avec donnÃ©es synthÃ©tiques
python main_orchestrator.py train

# EntraÃ®nement avec vos donnÃ©es
python main_orchestrator.py train --data your_data.csv --deploy
```

### 2. Comparaison des ModÃ¨les

```bash
# Comparaison complÃ¨te
python main_orchestrator.py compare --models all

# Comparaison sur scÃ©narios spÃ©cifiques
python main_orchestrator.py compare --scenarios standard high_anomaly
```

### 3. PrÃ©diction en Production

```bash
# PrÃ©diction sur nouvelles donnÃ©es
python main_orchestrator.py predict --input new_data.csv --output results.csv

# Utilisation d'un modÃ¨le spÃ©cifique
python main_orchestrator.py predict --input data.csv --model random_forest
```

### 4. Interface Python

```python
from main_orchestrator import MLOpsPipeline

# Initialisation
pipeline = MLOpsPipeline()

# Pipeline complÃ¨te
results = pipeline.run_full_pipeline(deploy=True)

# PrÃ©dictions
predictions = pipeline.predict_anomalies(new_data)
```

## ğŸ“š Documentation DÃ©taillÃ©e

### Structure des Fichiers

```
ğŸ“¦ mlops-anomaly-detection/
â”œâ”€â”€ ğŸ“„ base_anomaly_model.py      # Classe de base abstraite
â”œâ”€â”€ ğŸŒ³ isolation_forest_model.py  # ModÃ¨le Isolation Forest
â”œâ”€â”€ ğŸŒ² random_forest_model.py     # ModÃ¨le Random Forest  
â”œâ”€â”€ ğŸ§  lstm_model.py              # ModÃ¨le LSTM
â”œâ”€â”€ ğŸ”¬ model_comparison.py        # Comparaison des modÃ¨les
â”œâ”€â”€ ğŸ¯ main_orchestrator.py       # Orchestrateur principal
â”œâ”€â”€ âš™ï¸ config.json               # Configuration
â”œâ”€â”€ ğŸ§ª test_complete_pipeline.py  # Tests complets
â”œâ”€â”€ ğŸ³ kubernetes-manifests.yaml  # DÃ©ploiement K8s
â”œâ”€â”€ ğŸ“Š grafana-dashboard.json     # Dashboard Grafana
â”œâ”€â”€ ğŸš€ deploy_mlops_pipeline.sh   # Script de dÃ©ploiement
â””â”€â”€ ğŸ“– README.md                  # Cette documentation
```

### Classes et MÃ©thodes Principales

#### BaseAnomalyModel
- `generate_synthetic_data()` - GÃ©nÃ©ration de donnÃ©es d'entraÃ®nement
- `prepare_features()` - Engineering des features
- `fit()` - EntraÃ®nement avec MLflow tracking
- `predict()` - PrÃ©dictions d'anomalies
- `evaluate()` - Ã‰valuation des performances

#### ModÃ¨les SpÃ©cialisÃ©s
- `IsolationForestModel.find_optimal_contamination()` - Optimisation automatique
- `RandomForestModel.cross_validate()` - Validation croisÃ©e approfondie
- `LSTMModel.detect_temporal_anomalies()` - Analyse temporelle avancÃ©e

#### Pipeline OrchestrÃ©e
- `MLOpsPipeline.run_full_pipeline()` - ExÃ©cution bout en bout
- `ModelComparator.compare_models()` - Comparaison automatique

## âš™ï¸ Configuration

Le fichier `config.json` permet de configurer tous les aspects de la pipeline :

### Configuration des DonnÃ©es
```json
{
  "data": {
    "n_samples": 10000,
    "anomaly_rate": 0.05,
    "test_size": 0.2,
    "include_temporal": true
  }
}
```

### Configuration des ModÃ¨les
```json
{
  "models": {
    "isolation_forest": {
      "contamination": 0.05,
      "n_estimators": 100
    },
    "random_forest": {
      "n_estimators": 100,
      "max_depth": 15,
      "class_weight": "balanced"
    },
    "lstm": {
      "sequence_length": 10,
      "lstm_units": [50, 25],
      "epochs": 30
    }
  }
}
```

### Configuration d'Ã‰valuation
```json
{
  "evaluation": {
    "primary_metric": "f1_score",
    "min_accuracy": 0.80,
    "min_precision": 0.75,
    "min_recall": 0.75
  }
}
```

## ğŸš€ DÃ©ploiement

### DÃ©ploiement Local

```bash
# 1. DÃ©marrage des services MLflow
mlflow server --host 0.0.0.0 --port 5000

# 2. EntraÃ®nement et dÃ©ploiement
python main_orchestrator.py train --deploy

# 3. Monitoring
python validate_pipeline.py
```

### DÃ©ploiement Production (Kubernetes)

```bash
# 1. Configuration des namespaces
kubectl apply -f kubernetes-manifests.yaml

# 2. DÃ©ploiement automatisÃ©
./deploy_mlops_pipeline.sh

# 3. VÃ©rification du statut
kubectl get pods -n mlops-pipeline
```

### Services ExposÃ©s

| Service | Port | Description |
|---------|------|-------------|
| MLflow UI | 5000 | Interface de gestion des modÃ¨les |
| Grafana | 3000 | Dashboards de monitoring |
| Prometheus | 9090 | Collecte de mÃ©triques |
| API PrÃ©diction | 8000 | Endpoint de prÃ©diction |

### Variables d'Environnement

```bash
export MLFLOW_TRACKING_URI="http://localhost:5000"
export KAFKA_BOOTSTRAP_SERVERS="localhost:9092"
export PROMETHEUS_GATEWAY="localhost:9091"
```

## ğŸ§ª Tests

### Tests Unitaires

```bash
# Tests complets
python test_complete_pipeline.py

# Tests spÃ©cifiques
python -m unittest test_complete_pipeline.TestIsolationForestModel
python -m unittest test_complete_pipeline.TestRandomForestModel
python -m unittest test_complete_pipeline.TestLSTMModel
```

### Tests d'IntÃ©gration

```bash
# Test de la pipeline complÃ¨te
python -m unittest test_complete_pipeline.TestMLOpsPipeline

# Test de comparaison des modÃ¨les
python -m unittest test_complete_pipeline.TestModelComparison
```

### Tests de Performance

```bash
# Tests de charge et latence
python -m unittest test_complete_pipeline.TestPerformance

# Benchmark complet
python model_comparison.py
```

### Couverture de Tests

```bash
# Installation coverage
pip install coverage

# ExÃ©cution avec couverture
coverage run test_complete_pipeline.py
coverage report -m
coverage html
```

## ğŸ“Š Monitoring

### MÃ©triques CollectÃ©es

| MÃ©trique | Description | Type |
|----------|-------------|------|
| `kafka_messages_processed_total` | Messages traitÃ©s | Counter |
| `anomalies_detected_total` | Anomalies dÃ©tectÃ©es | Counter |
| `message_processing_seconds` | Temps de traitement | Histogram |
| `model_accuracy` | PrÃ©cision du modÃ¨le | Gauge |

### Dashboards Grafana

1. **Vue d'Ensemble Pipeline** - KPIs globaux
2. **DÃ©tection d'Anomalies** - Monitoring temps rÃ©el
3. **Performance ModÃ¨les** - MÃ©triques ML
4. **Infrastructure** - Ã‰tat des composants

### Alertes ConfigurÃ©es

- ğŸš¨ Pic d'anomalies (>5/min)
- âš ï¸ DÃ©gradation modÃ¨le (<80% prÃ©cision)
- ğŸ’¥ Erreurs pipeline
- ğŸŒ Latence Ã©levÃ©e (>100ms)

### MLflow Tracking

- ğŸ“Š Tracking automatique des expÃ©riences
- ğŸ† Comparaison des modÃ¨les
- ğŸ“¦ Registry des modÃ¨les
- ğŸ”„ Versioning automatique

## ğŸ¤ Contribution

### Guidelines de DÃ©veloppement

1. **Fork** le repository
2. **CrÃ©er** une branche feature (`git checkout -b feature/amazing-feature`)
3. **ImplÃ©menter** vos changements avec tests
4. **Tester** complÃ¨tement (`python test_complete_pipeline.py`)
5. **Commit** (`git commit -m 'Add amazing feature'`)
6. **Push** (`git push origin feature/amazing-feature`)
7. **Ouvrir** une Pull Request

### Standards de Code

- ğŸ **PEP 8** - Style Python
- ğŸ“ **Docstrings** - Documentation complÃ¨te
- ğŸ§ª **Tests** - Couverture >90%
- ğŸ” **Type Hints** - Annotations de types
- ğŸ“Š **Logging** - Logs structurÃ©s

### Structure des Commits

```
type(scope): description

feat(models): add LSTM temporal analysis
fix(pipeline): resolve memory leak in training
docs(readme): update installation instructions
test(lstm): add sequence preparation tests
```

## ğŸ†˜ Support

### FAQ

**Q: Comment ajouter un nouveau modÃ¨le ?**
R: HÃ©ritez de `BaseAnomalyModel` et implÃ©mentez les mÃ©thodes abstraites.

**Q: Comment configurer les alertes ?**
R: Modifiez la section `alerts` dans `config.json`.

**Q: Quelle configuration pour la production ?**
R: Utilisez `n_estimators=200+`, `epochs=50+`, validation croisÃ©e.

**Q: Comment dÃ©boguer une prÃ©diction ?**
R: Utilisez `explain_predictions()` pour l'interprÃ©tabilitÃ©.

### ProblÃ¨mes Courants

| ProblÃ¨me | Solution |
|----------|----------|
| MLflow non accessible | VÃ©rifiez `MLFLOW_TRACKING_URI` |
| LSTM lent | RÃ©duisez `sequence_length` et `epochs` |
| MÃ©moire insuffisante | Utilisez `batch_size` plus petit |
| Kafka timeout | VÃ©rifiez la configuration rÃ©seau |

### Contact et Support

- ğŸ“§ **Email** : mlops-team@company.com
- ğŸ’¬ **Slack** : #mlops-support
- ğŸ› **Issues** : [GitHub Issues](https://github.com/your-org/mlops-anomaly-detection/issues)
- ğŸ“– **Wiki** : [Documentation ComplÃ¨te](https://github.com/your-org/mlops-anomaly-detection/wiki)

---

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ™ Remerciements

- **Scikit-learn** pour les algorithmes ML
- **TensorFlow** pour les rÃ©seaux de neurones
- **MLflow** pour la gestion des modÃ¨les
- **Kubernetes** pour l'orchestration
- **Prometheus/Grafana** pour le monitoring

---

<div align="center">

**ğŸ¯ Mission : Transformer la supervision IT avec l'Intelligence Artificielle**

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange.svg)](https://tensorflow.org)
[![MLflow](https://img.shields.io/badge/MLflow-Ready-green.svg)](https://mlflow.org)
[![Kubernetes](https://img.shields.io/badge/Kubernetes-Native-blue.svg)](https://kubernetes.io)

*DÃ©veloppÃ© avec â¤ï¸ par l'Ã©quipe MLOps*

</div>
