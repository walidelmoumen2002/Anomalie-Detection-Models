"""
Isolation Forest Model for IT Anomaly Detection
===============================================

Mod√®le de d√©tection d'anomalies bas√© sur l'algorithme Isolation Forest.
Parfait pour la d√©tection d'anomalies non-supervis√©e dans les infrastructures IT.

Principes de l'Isolation Forest:
- Isole les anomalies en construisant des arbres al√©atoires
- Les anomalies sont plus faciles √† isoler (moins de splits n√©cessaires)
- Ne n√©cessite pas de donn√©es √©tiquet√©es
- Tr√®s efficace sur de gros volumes de donn√©es

Cas d'usage typiques:
- D√©tection d'anomalies syst√®me inconnues
- Monitoring continu sans supervision
- Premi√®re ligne de d√©fense contre les incidents

Author: MLOps Team
Date: June 2025
Version: 1.0
"""

import numpy as np
import pandas as pd
from sklearn.ensemble import IsolationForest
from sklearn.model_selection import GridSearchCV
import mlflow
import logging
from base_model import BaseAnomalyModel

logger = logging.getLogger(__name__)

class IsolationForestModel(BaseAnomalyModel):
    """
    Mod√®le de d√©tection d'anomalies utilisant Isolation Forest.
    
    L'Isolation Forest est particuli√®rement adapt√© pour:
    - La d√©tection d'anomalies sans supervision
    - Le traitement de gros volumes de donn√©es
    - L'identification d'outliers multivari√©s
    - La robustesse face au bruit
    
    Attributes:
        contamination (float): Proportion attendue d'anomalies dans les donn√©es
        n_estimators (int): Nombre d'arbres dans la for√™t
        max_samples (str/int): Nombre d'√©chantillons pour construire chaque arbre
        max_features (float): Proportion de features utilis√©es par arbre
        bootstrap (bool): Utilisation du bootstrap pour l'√©chantillonnage
        random_state (int): Graine al√©atoire pour reproductibilit√©
    """
    
    def __init__(self, contamination: float = 0.05, n_estimators: int = 100, 
                 max_samples: str = "auto", max_features: float = 1.0,
                 bootstrap: bool = False, random_state: int = 42):
        """
        Initialise le mod√®le Isolation Forest.
        
        Args:
            contamination (float): Proportion d'anomalies attendues (0.0 √† 0.5)
                                 - 0.05 = 5% d'anomalies (recommand√© pour IT)
                                 - 0.1 = 10% d'anomalies (environnement instable)
            n_estimators (int): Nombre d'arbres dans la for√™t
                              - 100: bon compromis performance/pr√©cision
                              - 200+: meilleure pr√©cision, plus lent
            max_samples (str/int): √âchantillons par arbre
                                 - "auto": min(256, n_samples)
                                 - int: nombre fixe d'√©chantillons
            max_features (float): Proportion de features par arbre (0.0 √† 1.0)
                                - 1.0: toutes les features (recommand√©)
                                - 0.5: la moiti√© des features (plus rapide)
            bootstrap (bool): √âchantillonnage avec remise
                            - False: sans remise (recommand√©)
                            - True: avec remise (plus de diversit√©)
            random_state (int): Graine al√©atoire pour reproductibilit√©
        
        Example:
            # Configuration standard pour IT monitoring
            model = IsolationForestModel(contamination=0.05, n_estimators=100)
            
            # Configuration haute performance
            model = IsolationForestModel(contamination=0.03, n_estimators=200, max_samples=512)
            
            # Configuration rapide pour gros volumes
            model = IsolationForestModel(contamination=0.1, n_estimators=50, max_features=0.8)
        """
        super().__init__(model_name="IsolationForest", model_type="unsupervised")
        
        # Param√®tres du mod√®le
        self.contamination = contamination
        self.n_estimators = n_estimators
        self.max_samples = max_samples
        self.max_features = max_features
        self.bootstrap = bootstrap
        self.random_state = random_state
        
        # Validation des param√®tres
        self._validate_parameters()
        
        logger.info(f"IsolationForest initialis√©: contamination={contamination}, "
                   f"n_estimators={n_estimators}")
    
    def _validate_parameters(self):
        """Valide les param√®tres du mod√®le."""
        if not 0.0 < self.contamination <= 0.5:
            raise ValueError("contamination doit √™tre entre 0.0 et 0.5")
        
        if self.n_estimators < 1:
            raise ValueError("n_estimators doit √™tre positif")
        
        if not 0.0 < self.max_features <= 1.0:
            raise ValueError("max_features doit √™tre entre 0.0 et 1.0")
    
    def _create_model(self, **kwargs):
        """
        Cr√©e l'instance Isolation Forest avec les param√®tres configur√©s.
        
        Args:
            **kwargs: Param√®tres additionnels pour surcharger la configuration
        
        Returns:
            IsolationForest: Instance configur√©e du mod√®le
        """
        # Fusion des param√®tres par d√©faut et additionnels
        params = {
            'contamination': self.contamination,
            'n_estimators': self.n_estimators,
            'max_samples': self.max_samples,
            'max_features': self.max_features,
            'bootstrap': self.bootstrap,
            'random_state': self.random_state,
            'n_jobs': -1,  # Utilise tous les CPUs disponibles
            'verbose': 0   # Pas de sortie verbose
        }
        params.update(kwargs)
        
        logger.info(f"Cr√©ation IsolationForest avec param√®tres: {params}")
        
        return IsolationForest(**params)
    
    def _fit_model(self, X_train, y_train=None):
        """
        Entra√Æne le mod√®le Isolation Forest.
        
        Note: y_train est ignor√© car Isolation Forest est non-supervis√©.
        
        Args:
            X_train: Features d'entra√Ænement normalis√©es
            y_train: Ignor√© (non-supervis√©)
        
        Returns:
            IsolationForest: Mod√®le entra√Æn√©
        """
        logger.info(f"Entra√Ænement sur {X_train.shape[0]} √©chantillons, {X_train.shape[1]} features")
        
        # Entra√Ænement du mod√®le
        self.model.fit(X_train)
        
        # Log des informations d'entra√Ænement
        logger.info("Entra√Ænement Isolation Forest termin√©")
        
        return self.model
    
    def _predict_anomalies(self, X):
        """
        Pr√©dit les anomalies avec Isolation Forest.
        
        Args:
            X: Features normalis√©es pour la pr√©diction
        
        Returns:
            np.array: Pr√©dictions binaires (1=anomalie, 0=normal)
        """
        # Isolation Forest retourne -1 pour anomalies, 1 pour normal
        raw_predictions = self.model.predict(X)
        
        # Conversion en format standard (1=anomalie, 0=normal)
        predictions = (raw_predictions == -1).astype(int)
        
        return predictions
    
    def get_anomaly_scores(self, X):
        """
        Calcule les scores d'anomalie pour chaque √©chantillon.
        
        Plus le score est faible (n√©gatif), plus l'√©chantillon est anormal.
        Utile pour classer les anomalies par s√©v√©rit√©.
        
        Args:
            X: Features pour le calcul des scores
        
        Returns:
            np.array: Scores d'anomalie (valeurs n√©gatives)
        
        Example:
            scores = model.get_anomaly_scores(X_test)
            # Anomalies les plus s√©v√®res
            most_anomalous = np.argsort(scores)[:10]
        """
        if not self.is_fitted:
            raise ValueError("Le mod√®le doit √™tre entra√Æn√© avant le calcul des scores")
        
        X_scaled = self.scaler.transform(X)
        scores = self.model.score_samples(X_scaled)
        
        return scores
    
    def get_decision_scores(self, X):
        """
        Calcule les scores de d√©cision pour chaque √©chantillon.
        
        Returns:
            np.array: Scores de d√©cision (plus proche de 0 = plus anormal)
        """
        if not self.is_fitted:
            raise ValueError("Le mod√®le doit √™tre entra√Æn√© avant le calcul des scores")
        
        X_scaled = self.scaler.transform(X)
        scores = self.model.decision_function(X_scaled)
        
        return scores
    
    def find_optimal_contamination(self, X, contamination_range=None, cv_folds=3):
        """
        Trouve le taux de contamination optimal par validation crois√©e.
        
        Cette m√©thode teste diff√©rents taux de contamination et s√©lectionne
        celui qui maximise la coh√©rence des pr√©dictions.
        
        Args:
            X: Features d'entra√Ænement
            contamination_range: Liste des taux √† tester
            cv_folds: Nombre de folds pour la validation crois√©e
        
        Returns:
            dict: R√©sultats de l'optimisation
        
        Example:
            results = model.find_optimal_contamination(X_train)
            print(f"Meilleur taux: {results['best_contamination']}")
        """
        if contamination_range is None:
            contamination_range = [0.01, 0.03, 0.05, 0.07, 0.1, 0.15, 0.2]
        
        logger.info(f"Recherche contamination optimale parmi: {contamination_range}")
        
        results = {
            'contamination_tested': contamination_range,
            'scores': [],
            'best_contamination': None,
            'best_score': -np.inf
        }
        
        X_scaled = self.scaler.fit_transform(X)
        
        for contamination in contamination_range:
            # Test du mod√®le avec ce taux de contamination
            test_model = IsolationForest(
                contamination=contamination,
                n_estimators=self.n_estimators,
                max_samples=self.max_samples,
                max_features=self.max_features,
                bootstrap=self.bootstrap,
                random_state=self.random_state,
                n_jobs=-1
            )
            
            # Validation crois√©e simplifi√©e
            fold_scores = []
            fold_size = len(X_scaled) // cv_folds
            
            for fold in range(cv_folds):
                start_idx = fold * fold_size
                end_idx = (fold + 1) * fold_size if fold < cv_folds - 1 else len(X_scaled)
                
                # Division train/validation
                val_indices = range(start_idx, end_idx)
                train_indices = list(range(0, start_idx)) + list(range(end_idx, len(X_scaled)))
                
                X_fold_train = X_scaled[train_indices]
                X_fold_val = X_scaled[val_indices]
                
                # Entra√Ænement et test
                test_model.fit(X_fold_train)
                scores = test_model.score_samples(X_fold_val)
                
                # Score de coh√©rence (variance des scores)
                fold_score = -np.var(scores)  # Plus c'est stable, mieux c'est
                fold_scores.append(fold_score)
            
            avg_score = np.mean(fold_scores)
            results['scores'].append(avg_score)
            
            if avg_score > results['best_score']:
                results['best_score'] = avg_score
                results['best_contamination'] = contamination
            
            logger.info(f"Contamination {contamination}: score = {avg_score:.4f}")
        
        logger.info(f"Meilleure contamination: {results['best_contamination']} "
                   f"(score: {results['best_score']:.4f})")
        
        # Mise √† jour du mod√®le avec le meilleur param√®tre
        self.contamination = results['best_contamination']
        
        return results
    
    def detect_realtime_anomalies(self, new_data, threshold_percentile=95):
        """
        D√©tecte les anomalies en temps r√©el avec seuillage adaptatif.
        
        Args:
            new_data: Nouvelles donn√©es √† analyser
            threshold_percentile: Percentile pour le seuil d'anomalie
        
        Returns:
            dict: R√©sultats de d√©tection avec scores et seuils
        """
        if not self.is_fitted:
            raise ValueError("Le mod√®le doit √™tre entra√Æn√© avant la d√©tection")
        
        # Pr√©dictions et scores
        predictions = self.predict(new_data)
        scores = self.get_anomaly_scores(new_data)
        decision_scores = self.get_decision_scores(new_data)
        
        # Seuil adaptatif bas√© sur la distribution des scores
        threshold = np.percentile(scores, threshold_percentile)
        
        # Anomalies s√©v√®res (en dessous du seuil)
        severe_anomalies = scores < threshold
        
        results = {
            'predictions': predictions,
            'anomaly_scores': scores,
            'decision_scores': decision_scores,
            'threshold': threshold,
            'severe_anomalies': severe_anomalies,
            'n_anomalies': np.sum(predictions),
            'n_severe_anomalies': np.sum(severe_anomalies),
            'anomaly_rate': np.mean(predictions),
            'severe_anomaly_rate': np.mean(severe_anomalies)
        }
        
        return results
    
    def explain_anomalies(self, X_anomalies, feature_names=None):
        """
        Analyse les caract√©ristiques des anomalies d√©tect√©es.
        
        Args:
            X_anomalies: Donn√©es identifi√©es comme anomalies
            feature_names: Noms des features
        
        Returns:
            dict: Analyse des anomalies
        """
        if feature_names is None:
            feature_names = self.feature_names or [f"feature_{i}" for i in range(X_anomalies.shape[1])]
        
        # Statistiques des anomalies
        anomaly_stats = pd.DataFrame(X_anomalies, columns=feature_names).describe()
        
        # Features les plus d√©viantes (z-score √©lev√©)
        z_scores = np.abs((X_anomalies - np.mean(X_anomalies, axis=0)) / (np.std(X_anomalies, axis=0) + 1e-8))
        avg_z_scores = np.mean(z_scores, axis=0)
        
        top_features = pd.DataFrame({
            'feature': feature_names,
            'avg_z_score': avg_z_scores
        }).sort_values('avg_z_score', ascending=False)
        
        analysis = {
            'n_anomalies': len(X_anomalies),
            'anomaly_statistics': anomaly_stats,
            'top_anomalous_features': top_features.head(10),
            'feature_correlations': pd.DataFrame(X_anomalies, columns=feature_names).corr()
        }
        
        return analysis


def demonstrate_isolation_forest():
    """
    D√©monstration compl√®te du mod√®le Isolation Forest.
    
    Cette fonction montre toutes les fonctionnalit√©s du mod√®le avec des exemples pratiques.
    """
    print("üå≤ D√âMONSTRATION ISOLATION FOREST")
    print("=" * 50)
    
    # 1. Initialisation du mod√®le
    print("\n1Ô∏è‚É£ Initialisation du mod√®le")
    model = IsolationForestModel(
        contamination=0.05,  # 5% d'anomalies attendues
        n_estimators=100,    # 100 arbres dans la for√™t
        random_state=42      # Pour reproductibilit√©
    )
    print(f"‚úÖ Mod√®le initialis√©: {model.model_name}")
    
    # 2. G√©n√©ration des donn√©es
    print("\n2Ô∏è‚É£ G√©n√©ration des donn√©es d'entra√Ænement")
    data = model.generate_synthetic_data(n_samples=5000, anomaly_rate=0.05)
    print(f"‚úÖ {len(data)} √©chantillons g√©n√©r√©s avec {data['is_anomaly'].sum()} anomalies")
    
    # 3. Pr√©paration des features
    print("\n3Ô∏è‚É£ Pr√©paration des features")
    X = model.prepare_features(data, include_temporal=True)
    y = data['is_anomaly']
    print(f"‚úÖ {X.shape[1]} features pr√©par√©es")
    
    # 4. Division des donn√©es
    print("\n4Ô∏è‚É£ Division train/test")
    X_train, X_test, y_train, y_test = model.split_data(X, y, test_size=0.2)
    print(f"‚úÖ Train: {len(X_train)}, Test: {len(X_test)}")
    
    # 5. Optimisation des hyperparam√®tres
    print("\n5Ô∏è‚É£ Optimisation du taux de contamination")
    optimization_results = model.find_optimal_contamination(X_train)
    print(f"‚úÖ Meilleur taux: {optimization_results['best_contamination']}")
    
    # 6. Entra√Ænement
    print("\n6Ô∏è‚É£ Entra√Ænement du mod√®le")
    training_metrics = model.fit(X_train)
    print(f"‚úÖ Entra√Ænement termin√© - Score: {training_metrics.get('score', 'N/A')}")
    
    # 7. √âvaluation
    print("\n7Ô∏è‚É£ √âvaluation sur donn√©es de test")
    eval_metrics = model.evaluate(X_test, y_test)
    print(f"‚úÖ Pr√©cision: {eval_metrics['accuracy']:.3f}")
    print(f"‚úÖ Rappel: {eval_metrics.get('recall', 'N/A')}")
    
    # 8. D√©tection en temps r√©el
    print("\n8Ô∏è‚É£ D√©tection d'anomalies en temps r√©el")
    rt_results = model.detect_realtime_anomalies(X_test[:100])
    print(f"‚úÖ {rt_results['n_anomalies']} anomalies d√©tect√©es sur 100 √©chantillons")
    print(f"‚úÖ {rt_results['n_severe_anomalies']} anomalies s√©v√®res")
    
    # 9. Analyse des anomalies
    print("\n9Ô∏è‚É£ Analyse des anomalies d√©tect√©es")
    anomaly_indices = np.where(rt_results['predictions'] == 1)[0]
    if len(anomaly_indices) > 0:
        X_anomalies = X_test.iloc[anomaly_indices]
        analysis = model.explain_anomalies(X_anomalies.values, X_anomalies.columns)
        print(f"‚úÖ {analysis['n_anomalies']} anomalies analys√©es")
        print("Top 3 features les plus anomales:")
        for _, row in analysis['top_anomalous_features'].head(3).iterrows():
            print(f"   - {row['feature']}: score {row['avg_z_score']:.2f}")
    
    # 10. R√©sum√© du mod√®le
    print("\nüîü R√©sum√© du mod√®le")
    model.summary()
    
    return model


# Exemple d'usage avanc√©
def advanced_isolation_forest_usage():
    """
    Exemples d'usage avanc√©s du mod√®le Isolation Forest.
    """
    print("\nüöÄ USAGE AVANC√â ISOLATION FOREST")
    print("=" * 50)
    
    # Configuration pour diff√©rents sc√©narios
    scenarios = {
        "Production stable": {
            "contamination": 0.02,
            "n_estimators": 150,
            "max_samples": "auto"
        },
        "Environnement test": {
            "contamination": 0.1,
            "n_estimators": 50,
            "max_samples": 256
        },
        "Haute pr√©cision": {
            "contamination": 0.03,
            "n_estimators": 300,
            "max_samples": 512
        }
    }
    
    for scenario_name, params in scenarios.items():
        print(f"\nüìä Sc√©nario: {scenario_name}")
        model = IsolationForestModel(**params)
        print(f"   Param√®tres: {params}")
        print(f"   Mod√®le pr√™t pour: {scenario_name}")


if __name__ == "__main__":
    # D√©monstration compl√®te
    trained_model = demonstrate_isolation_forest()
    
    # Usage avanc√©
    advanced_isolation_forest_usage()
    
    print("\nüéØ ISOLATION FOREST PR√äT POUR LA PRODUCTION!")
    print("Utilisez ce mod√®le pour la d√©tection d'anomalies non-supervis√©e.")
